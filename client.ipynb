{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 Query Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple-yet-powerful alternative to ChatGPT. It was created to easily access the OpenAI API [Text Completions](https://platform.openai.com/docs/guides/text-generation) endpoints (aka the GPT models) without having to use curl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies.\n",
    "\n",
    "1. Create a python virtual environment: `python3 -m venv .venv`\n",
    "\n",
    "2. Activate the virtual envirnment: `source .venv/bin/activate`\n",
    "\n",
    "3. Install the required dependencies: `pip install -r requirements.txt`\n",
    "\n",
    "4. Create a .env file to store your API secret: `echo 'OPENAI_API_KEY=\"##########\"' >> .env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from os import getenv, mkdir, getcwd, system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare configuration constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_CONFIG = {\n",
    "    'CWD': Path(getcwd()),\n",
    "    'ENCODING': 'utf-8'\n",
    "}\n",
    "\n",
    "GPT_CONFIG = {\n",
    "    'MODEL': 'gpt-4-turbo-preview',\n",
    "    'SYSTEM_PROMPT_PATH': SYSTEM_CONFIG['CWD'] / 'input' / 'system_prompt.txt',\n",
    "    'USER_PROMPT_PATH': SYSTEM_CONFIG['CWD'] / 'input' / 'user_prompt.txt',\n",
    "    'OUTPUT_FOLDER_PATH': SYSTEM_CONFIG['CWD'] / 'output',\n",
    "    'DEFAULT_SYS_PROMPT': \"\"\"#PERSONA\n",
    "You are an experienced problem solver.\n",
    "#END\n",
    "\n",
    "#INSTRUCTIONS\n",
    "1. You are given instructions, delimited by XML tags.\n",
    "2. Execute the insturctions and respond accordingly.\n",
    "#END\"\"\",\n",
    "    'DEFAULT_USR_PROMPT': \"\"\"<instructions>\n",
    "</instructions>\"\"\",\n",
    "}\n",
    "\n",
    "PROMPT_PATHS = (GPT_CONFIG['SYSTEM_PROMPT_PATH'], GPT_CONFIG['USER_PROMPT_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prompts from local textfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts_from_textfiles(prompt_paths: tuple) -> tuple:\n",
    "     with open(prompt_paths[0], 'r', encoding=SYSTEM_CONFIG['ENCODING']) as file:\n",
    "          sys = file.read()\n",
    "     with open(prompt_paths[1], 'r', encoding=SYSTEM_CONFIG['ENCODING']) as file:\n",
    "          usr = file.read()\n",
    "     prompts = (sys, usr)\n",
    "     return prompts\n",
    "\n",
    "try:\n",
    "     prompts = load_prompts_from_textfiles(PROMPT_PATHS)\n",
    "except FileNotFoundError as e: # ERROR HANDLING IF INPUT FOLDER DOES NOT EXIST.\n",
    "     print(f\"Caught: {e}\")\n",
    "     try:\n",
    "          mkdir(\"input\")\n",
    "     except FileExistsError:\n",
    "          print(\"Error: 'input' folder already exists. Delete to run this script.\")\n",
    "     # build paths\n",
    "     input_path = SYSTEM_CONFIG[\"CWD\"] / 'input'\n",
    "     sys_input_path = input_path / 'system_prompt.txt'\n",
    "     usr_input_path = input_path / 'user_prompt.txt'\n",
    "     # Native calls to echo\n",
    "     system(f\"echo \\\"{GPT_CONFIG['DEFAULT_SYS_PROMPT']}\\\" >> {sys_input_path}\")     \n",
    "     system(f\"echo \\\"{GPT_CONFIG['DEFAULT_USR_PROMPT']}\\\" >> {usr_input_path}\")\n",
    "     # Reminder to user to edit prompts\n",
    "     print(f\"You must edit prompt files: `{sys_input_path}` and `{usr_input_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build message for API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_builder(prompts: tuple) -> list:\n",
    "    msg = [\n",
    "        {\"role\": \"system\", \"content\": prompts[0]},\n",
    "        {\"role\": \"user\", \"content\": prompts[1]}\n",
    "    ]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query API and store response. Must be ran twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run again to confirm.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "response = None\n",
    "response_text = \"\"\n",
    "if (count == 0):\n",
    "    print(\"Run again to confirm.\")\n",
    "elif (count == 1):\n",
    "    # Run code here\n",
    "    client = OpenAI()\n",
    "    print(\"Querying GPT model. This may take a while...\")\n",
    "    response = client.chat.completions.create(model=GPT_CONFIG['MODEL'], messages=message_builder())\n",
    "    response_text = response.choices[0].message.content\n",
    "    count = 0\n",
    "else:\n",
    "    print(\"Error: Restart notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create response filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".md\n"
     ]
    }
   ],
   "source": [
    "filename = response_text[:20]\n",
    "filename = filename + \".md\"\n",
    "filename = filename.replace(\" \", \"_\")\n",
    "\n",
    "file_path = GPT_CONFIG['OUTPUT_FOLDER_PATH'] / filename\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write response to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: [Errno 2] No such file or directory: '/Users/nickkammerer/Documents/dev/jupyter-gpt/output/.md'\n",
      "Response written to /Users/nickkammerer/Documents/dev/jupyter-gpt/output/.md.\n"
     ]
    }
   ],
   "source": [
    "def write_file(file_path: Path, file_content: str) -> None:\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(file_content)\n",
    "    print(f\"Response written to {file_path}.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    write_file(file_path, response_text)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Warn: {e}\")\n",
    "    mkdir(GPT_CONFIG['OUTPUT_FOLDER_PATH'])\n",
    "    write_file(file_path, response_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(WIP) Using pandoc, write the markdown to pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandoc_output_file_path = str(file_path).split(\".\")[0] + '.pdf'\n",
    "#system_call = f\"pandoc {file_path} -o {pandoc_output_file_path}\"\n",
    "#\n",
    "#try:\n",
    "#    system(\"\")\n",
    "#except Exception as e:\n",
    "#    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
