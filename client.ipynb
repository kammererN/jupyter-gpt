{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 Query Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple-yet-powerful alternative to ChatGPT. It was created to easily access the OpenAI API [Text Completions](https://platform.openai.com/docs/guides/text-generation) endpoints (aka the GPT models) without having to use curl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies.\n",
    "\n",
    "1. Create a python virtual environment: `python3 -m venv .venv`\n",
    "\n",
    "2. Activate the virtual envirnment: `source .venv/bin/activate`\n",
    "\n",
    "3. Install the required dependencies: `pip install -r requirements.txt`\n",
    "\n",
    "4. Create a .env file to store your API secret: `echo 'OPENAI_API_KEY=\"##########\"' >> .env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from os import getenv, mkdir, getcwd, system\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare configuration constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_CONFIG = {\n",
    "    'CWD': Path(getcwd()),\n",
    "    'ENCODING': 'utf-8'\n",
    "}\n",
    "\n",
    "GPT_CONFIG = {\n",
    "    'MODEL': 'gpt-4-turbo-preview',\n",
    "    'SYSTEM_PROMPT_PATH': SYSTEM_CONFIG['CWD'] / 'input' / 'system_prompt.txt',\n",
    "    'USER_PROMPT_PATH': SYSTEM_CONFIG['CWD'] / 'input' / 'user_prompt.txt',\n",
    "    'OUTPUT_FOLDER_PATH': SYSTEM_CONFIG['CWD'] / 'output',\n",
    "    'DEFAULT_SYS_PROMPT': \"\"\"#PERSONA\n",
    "You are an experienced problem solver.\n",
    "#END\n",
    "\n",
    "#INSTRUCTIONS\n",
    "1. You are given instructions, delimited by XML tags.\n",
    "2. Execute the insturctions and respond accordingly.\n",
    "#END\"\"\",\n",
    "    'DEFAULT_USR_PROMPT': \"\"\"<instructions>\n",
    "</instructions>\"\"\",\n",
    "}\n",
    "\n",
    "PROMPT_PATHS = (GPT_CONFIG['SYSTEM_PROMPT_PATH'], GPT_CONFIG['USER_PROMPT_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prompts from local textfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts_from_textfiles(prompt_paths: tuple) -> tuple:\n",
    "     with open(prompt_paths[0], 'r', encoding=SYSTEM_CONFIG['ENCODING']) as file:\n",
    "          sys = file.read()\n",
    "     with open(prompt_paths[1], 'r', encoding=SYSTEM_CONFIG['ENCODING']) as file:\n",
    "          usr = file.read()\n",
    "     prompts = (sys, usr)\n",
    "     return prompts\n",
    "\n",
    "try:\n",
    "     prompts = load_prompts_from_textfiles(PROMPT_PATHS)\n",
    "except FileNotFoundError as e: # ERROR HANDLING IF INPUT FOLDER DOES NOT EXIST.\n",
    "     print(f\"Caught: {e}\")\n",
    "     try:\n",
    "          mkdir(\"input\")\n",
    "     except FileExistsError:\n",
    "          print(\"Error: 'input' folder already exists. Delete to run this script.\")\n",
    "     # build paths\n",
    "     input_path = SYSTEM_CONFIG[\"CWD\"] / 'input'\n",
    "     sys_input_path = input_path / 'system_prompt.txt'\n",
    "     usr_input_path = input_path / 'user_prompt.txt'\n",
    "     # Native calls to echo\n",
    "     system(f\"echo \\\"{GPT_CONFIG['DEFAULT_SYS_PROMPT']}\\\" >> {sys_input_path}\")     \n",
    "     system(f\"echo \\\"{GPT_CONFIG['DEFAULT_USR_PROMPT']}\\\" >> {usr_input_path}\")\n",
    "     # Reminder to user to edit prompts\n",
    "     print(f\"You must edit prompt files: `{sys_input_path}` and `{usr_input_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build message for API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_builder(prompts: tuple) -> list:\n",
    "    msg = [\n",
    "        {\"role\": \"system\", \"content\": prompts[0]},\n",
    "        {\"role\": \"user\", \"content\": prompts[1]}\n",
    "    ]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query API and store response. Must be ran twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying GPT model. This may take a while...\n",
      "...response returned.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "print(\"Querying GPT model. This may take a while...\")\n",
    "response = client.chat.completions.create(model=GPT_CONFIG['MODEL'], messages=message_builder(prompts))\n",
    "print(\"...response returned.\")\n",
    "response_text = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create response filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-16_19-29-16.md\n"
     ]
    }
   ],
   "source": [
    "filename = str(datetime.now()).split(\".\")[0]\n",
    "filename = filename + \".md\"\n",
    "filename = filename.replace(\" \", \"_\")\n",
    "filename = filename.replace(\":\", \"-\")\n",
    "\n",
    "file_path = GPT_CONFIG['OUTPUT_FOLDER_PATH'] / filename\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write response to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response written to C:\\dev\\jupyter-gpt\\output\\2024-04-16_19-29-16.md.\n"
     ]
    }
   ],
   "source": [
    "def write_file(file_path: Path, file_content: str) -> None:\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(file_content)\n",
    "    print(f\"Response written to {file_path}.\")\n",
    "\n",
    "try:\n",
    "    write_file(file_path, response_text)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Warn: {e}\")\n",
    "    mkdir(GPT_CONFIG['OUTPUT_FOLDER_PATH'])\n",
    "    write_file(file_path, response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
